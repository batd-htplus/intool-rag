version: "3.9"

services:
    qdrant:
        image: qdrant/qdrant:v1.9.3
        ports:
            - "6333:6333"
        volumes:
            - qdrant_storage:/qdrant/storage
        networks:
            - rag_network

    ai-service:
        build:
            context: .
            dockerfile: ai/Dockerfile.model
        ports:
            - "8002:8002"
        environment:
            EMBEDDING_MODEL: BAAI/bge-m3
            EMBEDDING_DEVICE: cpu

            LLM_BACKEND: ollama
            LLM_MODEL: phi3:mini
            OLLAMA_BASE_URL: http://host.docker.internal:11434

            LOG_LEVEL: DEBUG
        volumes:
            - ./ai:/app/ai
            - model_cache:/app/.cache
        networks:
            - rag_network
        extra_hosts:
            - "host.docker.internal:host-gateway"
        command: >
            uvicorn ai.api:app --host 0.0.0.0 --port 8002 --log-level debug

    rag-service:
        build:
            context: .
            dockerfile: rag/Dockerfile.rag
        ports:
            - "8001:8001"
        environment:
            MODEL_SERVICE_URL: http://ai-service:8002
            QDRANT_URL: http://qdrant:6333
        volumes:
            - ./rag:/app/rag
            - ./storages:/storage
        networks:
            - rag_network
        command: >
            uvicorn rag.api:app --host 0.0.0.0 --port 8001 --log-level debug
        depends_on:
            - qdrant
            - ai-service

    backend:
        build:
            context: ./backend
            dockerfile: app/Dockerfile
        ports:
            - "8000:8000"
        environment:
            RAG_SERVICE_URL: http://rag-service:8001
        volumes:
            - ./backend:/app
        networks:
            - rag_network
        command: >
            uvicorn app.main:app --host 0.0.0.0 --port 8000 --log-level debug
        depends_on:
            - rag-service

    webui:
        image: ghcr.io/open-webui/open-webui:latest
        ports:
            - "3000:8080"
        environment:
            OPENAI_API_BASE_URL: http://backend:8000/v1
            OLLAMA_BASE_URL: http://host.docker.internal:11434
            ENABLE_RAG: "false"
            ENABLE_EMBEDDINGS: "false"
        networks:
            - rag_network
        extra_hosts:
            - "host.docker.internal:host-gateway"

networks:
    rag_network:

volumes:
    qdrant_storage:
    model_cache:
