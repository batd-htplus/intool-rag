#!/bin/bash
# Download models via Ollama

set -e

echo "ğŸ“¥ Downloading models via Ollama..."
echo ""

# Check if Ollama is running
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âš ï¸  Ollama is not running. Starting Ollama service..."
    sudo systemctl start ollama || {
        echo "âŒ Cannot start Ollama. Please start manually: sudo systemctl start ollama"
        exit 1
    }
    sleep 3
fi

echo "ğŸ“¥ Pulling Qwen2.5-7B model via Ollama..."
ollama pull qwen2.5:7b

echo ""
echo "âœ… Model downloaded via Ollama!"
echo ""
echo "ğŸ“‹ Available models:"
ollama list
echo ""
echo "ğŸ’¡ To use Ollama with RAG service:"
echo "   USE_OLLAMA=true docker compose up"
echo ""
echo "ğŸ’¡ Models location: ~/.ollama/models/"
echo ""

